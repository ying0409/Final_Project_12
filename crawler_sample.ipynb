{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from requests_html import HTML\n",
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleCrawler():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.url = 'https://www.google.com/search?q='    \n",
    "    #  URL 萃取 From Google Search上 , using 第三方套件\n",
    "    #  https://python-googlesearch.readthedocs.io/en/latest/\n",
    "    def google_url_search_byOpenSource(query,tbs='qdr:m',num=10):\n",
    "        array_url = [url for url in search('tsmc', tbs='qdr:m' , num=10)]\n",
    "        return array_url\n",
    "    # 網路擷取器\n",
    "    def get_source(self,url):\n",
    "        try:\n",
    "            session = HTMLSession()\n",
    "            response = session.get(url)\n",
    "            return response\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "    # URL 萃取 From Google Search上\n",
    "    def scrape_google(self,query):\n",
    "\n",
    "        response = self.get_source(self.url + query)\n",
    "        links = list(response.html.absolute_links)\n",
    "        google_domains = ('https://www.google.', \n",
    "                          'https://google.', \n",
    "                          'https://webcache.googleusercontent.', \n",
    "                          'http://webcache.googleusercontent.', \n",
    "                          'https://policies.google.',\n",
    "                          'https://support.google.',\n",
    "                          'https://maps.google.')\n",
    "\n",
    "        for url in links[:]:\n",
    "            if url.startswith(google_domains):\n",
    "                links.remove(url)\n",
    "        return links\n",
    "    \n",
    "# URL萃取器，有link之外，也有標題\n",
    "#     qdr:h (past hour)\n",
    "#     qdr:d (past day)\n",
    "#     qdr:w (past week)\n",
    "#     qdr:m (past month)\n",
    "#     qdr:y (past year)\n",
    "    def google_search(self,query,timeline='',page='0'):\n",
    "        url = self.url + query + '&tbs={timeline}&start={page}'.format(timeline=timeline,page=page)\n",
    "        print('[Check][URL] URL : {url}'.format(url=url))\n",
    "        response = self.get_source(self.url + query)\n",
    "        return self.parse_googleResults(response)\n",
    "    # Google Search Result Parsing\n",
    "    def parse_googleResults(self,response):\n",
    "\n",
    "        css_identifier_result = \"tF2Cxc\"\n",
    "        css_identifier_title = \"h3\"\n",
    "        css_identifier_link = \"yuRUbf\"\n",
    "        css_identifier_text = \"VwiC3b\"\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        results = soup.findAll(\"div\", {\"class\": css_identifier_result})\n",
    "        output = []\n",
    "        for result in results:\n",
    "            item = {\n",
    "                'title': result.find(css_identifier_title).get_text(),\n",
    "                'link': result.find(\"div\", {\"class\": css_identifier_link}).find(href=True)['href'],\n",
    "                'text': result.find(\"div\", {\"class\": css_identifier_text}).get_text()\n",
    "            }\n",
    "            output.append(item)\n",
    "        return output\n",
    "    \n",
    "    # 網頁解析器\n",
    "    def html_parser(self,htmlText):\n",
    "        soup = BeautifulSoup(htmlText, 'html.parser')\n",
    "        return soup\n",
    "    # 解析後，取<p>文字\n",
    "    def html_getText(self,soup):\n",
    "        orignal_text = ''\n",
    "        for el in soup.find_all('p'):\n",
    "            orignal_text += ''.join(el.find_all(text=True))\n",
    "        return orignal_text\n",
    "    \n",
    "    def word_count(self, text):\n",
    "        counts = dict()\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = word_tokenize(text)\n",
    "        #words = text.replace(',','').split()\n",
    "        for word in words:\n",
    "            if word not in stop_words:\n",
    "                if word in counts:\n",
    "                    counts[word] += 1\n",
    "                else:\n",
    "                    counts[word] = 1\n",
    "        return counts\n",
    "    def get_wordcount_json(self,whitelist , dict_data):\n",
    "        data_array = []\n",
    "        for i in whitelist:\n",
    "            json_data = {\n",
    "                'Date' : 'Week1',\n",
    "                'Company' : i , \n",
    "                'Count' : dict_data[i]\n",
    "            }\n",
    "            data_array.append(json_data)\n",
    "        return data_array\n",
    "    def jsonarray_toexcel(self,data_array):\n",
    "        df = pd.DataFrame(data=data_array)\n",
    "        df.to_excel('result.xlsx' , index=False)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 程式使用情境\n",
    "### 1. 用程式去呼叫Google網頁伺服器，然後將顯示出來的URL，抓出來。 (支援換頁及限縮搜尋時間)\n",
    "### 2. 對我們要的URL，進行萃取，取得文字內容。\n",
    "### 3. 將文字內容，進行word count計算。\n",
    "### 4. 將word count結果儲存到Excel，以利分析之使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 在Google上輸入關鍵字，然後將顯示出來的URL，抓出來。 (支援換頁及限縮收尋時間)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用google_search 這支Function\n",
    "- 參數使用 timeline : 搜尋時間 => 參數可以參考qdr:h (past hour), qdr:d (past day),qdr:w (past week),qdr:m (past month),qdr:y (past year)\n",
    "- 參數使用 page : 換頁\n",
    "```\n",
    "def google_search(self,query,timeline='',page='0'):\n",
    "    url = self.url + query + '&tbs={timeline}&start={page}'.format(timeline=timeline,page=page)\n",
    "    print('[Check][URL] URL : {url}'.format(url=url))\n",
    "    response = self.get_source(self.url + query)\n",
    "    return self.parse_googleResults(response)\n",
    "```\n",
    "    \n",
    "####  這邊用到get_source及parse_googleResults，兩支Function，為了解析Google Search網路資源，並將URL/標題/內文，找出來。\n",
    "```\n",
    "def get_source(self,url):\n",
    "    try:\n",
    "        session = HTMLSession()\n",
    "        response = session.get(url)\n",
    "        return response\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "def parse_googleResults(self,response):\n",
    "        css_identifier_result = \"tF2Cxc\"\n",
    "        css_identifier_title = \"h3\"\n",
    "        css_identifier_link = \"yuRUbf\"\n",
    "        css_identifier_text = \"VwiC3b\"\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        results = soup.findAll(\"div\", {\"class\": css_identifier_result})\n",
    "        output = []\n",
    "        for result in results:\n",
    "            item = {\n",
    "                'title': result.find(css_identifier_title).get_text(),\n",
    "                'link': result.find(\"div\", {\"class\": css_identifier_link}).find(href=True)['href'],\n",
    "                'text': result.find(\"div\", {\"class\": css_identifier_text}).get_text()\n",
    "            }\n",
    "            output.append(item)\n",
    "        return output ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Check][URL] URL : https://www.google.com/search?q=TSMC ASML&tbs=qdr:w&start=10\n",
      "[{'title': 'Better Semiconductor Stock: ASML vs. TSMC | The Motley Fool', 'link': 'https://www.fool.com/investing/2021/04/21/better-semiconductor-stock-asml-vs-tsmc/', 'text': \"21 Apr 2021 — TSMC trades at 26 times forward earnings, which is much lower than ASML's forward P/E ratio of 45. TSMC's forward dividend yield of 1.5% is also\\xa0...\"}, {'title': 'Intel places ASML order to step up TSMC competition - Taipei ...', 'link': 'https://taipeitimes.com/News/biz/archives/2022/01/20/2003771688', 'text': \"20 Jan 2022 — Intel Corp yesterday said it has placed its first order with ASML Holding NV to purchase the semiconductor industry's first TWINSCAN EXE:\\xa0...\"}, {'title': \"ASML is the key to Intel's Resurrection Just like ASML helped...\", 'link': 'https://semiwiki.com/semiconductor-services/semiconductor-advisors/302806-asml-is-the-key-to-intels-resurrection-just-like-asml-helped-tsmc-beat-intel/', 'text': \"8 Sept 2021 — Intel's profits on its ASML investment helped prop up its weak performance. It was a great deal for ASML and Intel, TSMC & Samsung, a true win/\\xa0...\"}]\n"
     ]
    }
   ],
   "source": [
    "query = \"TSMC ASML\"\n",
    "crawler = GoogleCrawler()\n",
    "results = crawler.google_search(query , 'qdr:w' , '10')\n",
    "print(results[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 對我們要的URL，進行萃取，取得文字內容。\n",
    "- 使用get_source 這支Function，取得網路資源後，\n",
    "- 使用html_parser 這支Function，將網路資源進行解析。\n",
    "- 使用html_getText 這支Function，將我要的區塊p tag的文字取出來。\n",
    "```\n",
    "def get_source(self,url):\n",
    "    try:\n",
    "        session = HTMLSession()\n",
    "        response = session.get(url)\n",
    "        return response\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "def html_parser(self,htmlText):\n",
    "    soup = BeautifulSoup(htmlText, 'html.parser')\n",
    "    return soup\n",
    "def html_getText(self,soup):\n",
    "    orignal_text = ''\n",
    "    for el in soup.find_all('p'):\n",
    "        orignal_text += ''.join(el.find_all(text=True))\n",
    "    return orignal_text```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel Corp yesterday said it has placed its first order with ASML Holding NV to purchase the semicon\n"
     ]
    }
   ],
   "source": [
    "Target_URL = 'https://taipeitimes.com/News/biz/archives/2022/01/20/2003771688'\n",
    "response = crawler.get_source(Target_URL)\n",
    "soup = crawler.html_parser(response.text)\n",
    "orignal_text = crawler.html_getText(soup)\n",
    "print(orignal_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 將文字內容，進行word count計算\n",
    "#### 使用word_count function，將一篇文章內容，進行各文字的count個數\n",
    "```\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "def word_count(self, text):\n",
    "        counts = dict()\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = word_tokenize(text)\n",
    "        #words = text.replace(',','').split()\n",
    "        for word in words:\n",
    "            if word not in stop_words:\n",
    "                if word in counts:\n",
    "                    counts[word] += 1\n",
    "                else:\n",
    "                    counts[word] = 1\n",
    "        return counts ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intel': 5,\n",
       " 'Corp': 1,\n",
       " 'yesterday': 3,\n",
       " 'said': 20,\n",
       " 'placed': 1,\n",
       " 'first': 7,\n",
       " 'order': 2,\n",
       " 'ASML': 7,\n",
       " 'Holding': 1,\n",
       " 'NV': 1,\n",
       " 'purchase': 3,\n",
       " 'semiconductor': 8,\n",
       " 'industry': 6,\n",
       " '’': 17,\n",
       " 'TWINSCAN': 5,\n",
       " 'EXE': 1,\n",
       " ':': 6,\n",
       " '5200': 1,\n",
       " 'system': 8,\n",
       " ',': 46,\n",
       " 'US': 6,\n",
       " 'chip': 4,\n",
       " 'giant': 1,\n",
       " 'aims': 2,\n",
       " 'compete': 1,\n",
       " 'Taiwan': 8,\n",
       " 'Semiconductor': 5,\n",
       " 'Manufacturing': 5,\n",
       " 'Co': 4,\n",
       " '(': 9,\n",
       " 'TSMC': 7,\n",
       " '台積電': 3,\n",
       " ')': 9,\n",
       " 'advancing': 1,\n",
       " '2-nanometer': 4,\n",
       " 'process': 1,\n",
       " 'technology': 6,\n",
       " '.': 22,\n",
       " 'The': 12,\n",
       " 'Dutch': 1,\n",
       " 'equipment': 1,\n",
       " 'maker': 1,\n",
       " 'EXE:5200': 2,\n",
       " 'extreme': 1,\n",
       " 'ultraviolet': 1,\n",
       " 'EUV': 4,\n",
       " 'high-volume': 1,\n",
       " 'production': 3,\n",
       " 'high': 2,\n",
       " 'numerical': 1,\n",
       " 'aperture': 1,\n",
       " 'NA': 1,\n",
       " 'produce': 2,\n",
       " '220': 1,\n",
       " 'wafers': 2,\n",
       " 'per': 1,\n",
       " 'hour': 1,\n",
       " '150': 1,\n",
       " 'previous': 1,\n",
       " 'generation': 1,\n",
       " 'EXE:5000': 2,\n",
       " 'handle': 1,\n",
       " 'launch': 1,\n",
       " 'new': 5,\n",
       " '2024': 2,\n",
       " 'Photo': 1,\n",
       " 'ReutersASML': 1,\n",
       " 'president': 3,\n",
       " 'chief': 2,\n",
       " 'officer': 2,\n",
       " 'Martin': 1,\n",
       " 'van': 1,\n",
       " 'den': 1,\n",
       " 'Brink': 1,\n",
       " 'statement': 3,\n",
       " '“': 8,\n",
       " 'delivers': 1,\n",
       " 'continued': 2,\n",
       " 'lithographic': 1,\n",
       " 'improvements': 1,\n",
       " 'reduced': 1,\n",
       " 'complexity': 1,\n",
       " 'cost': 2,\n",
       " 'cycle': 1,\n",
       " 'time': 1,\n",
       " 'energy': 3,\n",
       " 'needs': 1,\n",
       " 'drive': 1,\n",
       " 'affordable': 1,\n",
       " 'scaling': 1,\n",
       " 'well': 1,\n",
       " 'next': 3,\n",
       " 'decade.': 1,\n",
       " '”': 7,\n",
       " 'Announcing': 1,\n",
       " 'deal': 1,\n",
       " 'executive': 2,\n",
       " 'vice': 1,\n",
       " 'general': 1,\n",
       " 'manager': 1,\n",
       " 'development': 1,\n",
       " 'Ann': 1,\n",
       " 'Kelleher': 1,\n",
       " 'Working': 1,\n",
       " 'closely': 1,\n",
       " 'harness': 1,\n",
       " 'high-NA': 1,\n",
       " 'high-resolution': 1,\n",
       " 'patterning': 1,\n",
       " 'one': 1,\n",
       " 'ways': 1,\n",
       " 'continue': 1,\n",
       " 'Moore': 1,\n",
       " 'Law': 1,\n",
       " 'maintain': 1,\n",
       " 'strong': 1,\n",
       " 'history': 1,\n",
       " 'progression': 1,\n",
       " 'smallest': 1,\n",
       " 'geometries.': 1,\n",
       " '2018': 1,\n",
       " 'company': 3,\n",
       " 'reflects': 1,\n",
       " 'collaboration': 1,\n",
       " 'marks': 1,\n",
       " 'beginning': 1,\n",
       " '2025': 2,\n",
       " 'also': 1,\n",
       " 'likely': 1,\n",
       " 'buy': 1,\n",
       " 'expected': 2,\n",
       " 'introduce': 1,\n",
       " 'supply': 2,\n",
       " 'chain': 1,\n",
       " 'source': 2,\n",
       " 'told': 1,\n",
       " 'Taipei': 3,\n",
       " 'Times': 1,\n",
       " 'Placing': 1,\n",
       " 'mean': 1,\n",
       " 'massively': 1,\n",
       " 'chips': 7,\n",
       " 'tool': 1,\n",
       " 'adding': 2,\n",
       " 'still': 4,\n",
       " 'long': 1,\n",
       " 'way': 1,\n",
       " 'go': 1,\n",
       " 'catching': 1,\n",
       " 'commercializing': 1,\n",
       " 'would': 6,\n",
       " 'enter': 1,\n",
       " 'market': 1,\n",
       " 'firm': 3,\n",
       " 'highest-performing': 1,\n",
       " 'available': 1,\n",
       " 'Separately': 1,\n",
       " 'expect': 1,\n",
       " 'factory': 1,\n",
       " 'fire': 3,\n",
       " 'Germany': 1,\n",
       " 'disrupt': 1,\n",
       " 'output': 2,\n",
       " 'Berlin': 1,\n",
       " 'facility': 1,\n",
       " 'early': 1,\n",
       " 'month': 2,\n",
       " 'extinguished': 1,\n",
       " 'within': 1,\n",
       " 'two': 2,\n",
       " 'hours': 2,\n",
       " 'expects': 1,\n",
       " 'ship': 1,\n",
       " '55': 1,\n",
       " 'systems': 1,\n",
       " 'year': 9,\n",
       " 'We': 1,\n",
       " 'able': 1,\n",
       " 'put': 1,\n",
       " 'couple': 1,\n",
       " 'significant': 2,\n",
       " 'damage': 1,\n",
       " 'Peter': 1,\n",
       " 'Wennink': 2,\n",
       " 'Because': 1,\n",
       " 'hard': 1,\n",
       " 'work': 1,\n",
       " 'creativity': 1,\n",
       " 'currently': 1,\n",
       " 'believe': 1,\n",
       " 'manage': 1,\n",
       " 'situation': 1,\n",
       " 'see': 1,\n",
       " 'impact': 1,\n",
       " '2022.': 1,\n",
       " 'demand': 1,\n",
       " '40': 1,\n",
       " '50': 2,\n",
       " 'percent': 5,\n",
       " 'maximum': 1,\n",
       " 'capacity': 2,\n",
       " 'take': 2,\n",
       " 'three': 2,\n",
       " 'years': 1,\n",
       " 'get': 1,\n",
       " 'nice': 1,\n",
       " 'balance': 1,\n",
       " 'demand.': 1,\n",
       " 'shipments': 1,\n",
       " 'increase': 2,\n",
       " 'added': 1,\n",
       " 'Additional': 1,\n",
       " 'reporting': 1,\n",
       " 'Bloomberg': 1,\n",
       " 'TOO': 1,\n",
       " 'COSTLY': 1,\n",
       " 'founder': 2,\n",
       " 'Morris': 2,\n",
       " 'Chang': 3,\n",
       " 'assumption': 1,\n",
       " 'Oregon': 1,\n",
       " 'similar': 1,\n",
       " '‘': 1,\n",
       " 'naive': 1,\n",
       " 'efforts': 1,\n",
       " 'onshore': 1,\n",
       " 'manufacturing': 4,\n",
       " 'semiconductors': 1,\n",
       " 'wasteful': 1,\n",
       " 'expensive': 1,\n",
       " 'exercise': 1,\n",
       " 'futility': 1,\n",
       " 'due': 1,\n",
       " 'lack': 1,\n",
       " 'talent': 2,\n",
       " 'costs': 1,\n",
       " '張忠謀': 1,\n",
       " 'Tuesday': 2,\n",
       " 'made': 1,\n",
       " 'remarks': 1,\n",
       " 'interview': 1,\n",
       " 'Brookings': 1,\n",
       " 'Institution': 1,\n",
       " 'latest': 1,\n",
       " 'podcast': 1,\n",
       " 'theme': 1,\n",
       " 'Can': 1,\n",
       " 'return': 1,\n",
       " '?': 1,\n",
       " 'veteran': 1,\n",
       " 'today': 2,\n",
       " 'good': 1,\n",
       " 'position': 1,\n",
       " 'terms': 1,\n",
       " 'design': 1,\n",
       " 'lacks': 1,\n",
       " 'sufficient': 1,\n",
       " 'I': 1,\n",
       " 'really': 1,\n",
       " 'think': 1,\n",
       " 'SHARING': 1,\n",
       " 'INNOVATION': 1,\n",
       " 'With': 1,\n",
       " 'world': 2,\n",
       " 'leading': 1,\n",
       " 'research': 1,\n",
       " 'institute': 1,\n",
       " 'Belgium': 1,\n",
       " 'looking': 1,\n",
       " 'attract': 1,\n",
       " 'expertise': 1,\n",
       " 'help': 1,\n",
       " 'manufacture': 1,\n",
       " 'Europe': 1,\n",
       " 'Focusing': 1,\n",
       " 'bilateral': 1,\n",
       " 'cooperation': 1,\n",
       " 'Taiwan-Belgium': 1,\n",
       " 'Joint': 1,\n",
       " 'Business': 1,\n",
       " 'Council': 1,\n",
       " 'meeting': 2,\n",
       " 'important': 1,\n",
       " 'annual': 1,\n",
       " 'business': 2,\n",
       " 'event': 1,\n",
       " 'countries': 1,\n",
       " 'place': 1,\n",
       " 'Thursday': 1,\n",
       " 'week': 1,\n",
       " 'Belgian': 3,\n",
       " 'Office': 1,\n",
       " 'Due': 1,\n",
       " 'COVID-19': 1,\n",
       " 'second': 1,\n",
       " 'consecutive': 1,\n",
       " 'hybrid': 1,\n",
       " 'Webinar': 1,\n",
       " 'Taiwanese': 2,\n",
       " 'representatives': 1,\n",
       " 'gathered': 1,\n",
       " 'counterparts': 1,\n",
       " 'joining': 1,\n",
       " 'online': 1,\n",
       " 'office': 2,\n",
       " 'primary': 1,\n",
       " 'focus': 1,\n",
       " 'given': 1,\n",
       " 'leader': 1,\n",
       " 'field': 1,\n",
       " 'amid': 1,\n",
       " 'global': 1,\n",
       " 'shortage': 1,\n",
       " 'EU': 1,\n",
       " 'February': 1,\n",
       " 'unveiled': 1,\n",
       " 'European': 1,\n",
       " 'Chips': 1,\n",
       " 'SOUTHERN': 1,\n",
       " 'STAKES': 1,\n",
       " 'Approved': 2,\n",
       " 'Chinese': 1,\n",
       " 'investments': 2,\n",
       " 'dropped': 1,\n",
       " 'value': 1,\n",
       " 'foreign': 1,\n",
       " 'direct': 1,\n",
       " 'FDIs': 1,\n",
       " 'approved': 2,\n",
       " 'government': 1,\n",
       " 'rose': 1,\n",
       " 'months': 1,\n",
       " '125': 1,\n",
       " 'earlier': 2,\n",
       " 'funds': 1,\n",
       " 'poured': 1,\n",
       " 'green': 1,\n",
       " 'projects': 1,\n",
       " 'along': 1,\n",
       " 'Hitachi': 1,\n",
       " 'Ltd': 1,\n",
       " 'stake': 1,\n",
       " 'elevator': 1,\n",
       " 'supplier': 1,\n",
       " 'Investment': 1,\n",
       " 'Commission': 1,\n",
       " 'Wednesday': 1,\n",
       " 'FDI': 3,\n",
       " 'January': 1,\n",
       " 'last': 3,\n",
       " 'totaled': 1,\n",
       " '$': 2,\n",
       " '2.75': 1,\n",
       " 'billion': 2,\n",
       " '125.61': 1,\n",
       " 'number': 1,\n",
       " 'applications': 1,\n",
       " 'fell': 1,\n",
       " '15.36': 1,\n",
       " '562': 1,\n",
       " 'data': 1,\n",
       " 'showed': 1,\n",
       " 'surge': 1,\n",
       " 'came': 1,\n",
       " 'Denmark-based': 1,\n",
       " 'developer': 1,\n",
       " 'Copenhagen': 1,\n",
       " 'Infrastructure': 1,\n",
       " 'Partners': 1,\n",
       " 'K/S': 1,\n",
       " 'CIP': 1,\n",
       " 'construction': 2,\n",
       " 'wafer': 2,\n",
       " 'fab': 1,\n",
       " 'Japan': 3,\n",
       " 'run': 1,\n",
       " 'joint': 2,\n",
       " 'venture': 2,\n",
       " 'led': 1,\n",
       " 'begin': 2,\n",
       " 'Advanced': 1,\n",
       " 'Inc': 1,\n",
       " 'JASM': 1,\n",
       " 'signed': 1,\n",
       " 'agreement': 1,\n",
       " 'authorities': 1,\n",
       " 'Kikuyo-machi': 1,\n",
       " 'Kumamoto': 1,\n",
       " 'Prefecture': 1,\n",
       " 'Yuichi': 1,\n",
       " 'Horita': 2,\n",
       " 'announcing': 1,\n",
       " 'schedule': 1,\n",
       " 'plant': 2,\n",
       " 'shipping': 1,\n",
       " 'products': 1,\n",
       " 'December': 1,\n",
       " 'In': 1,\n",
       " 'November': 1,\n",
       " 'largest': 1,\n",
       " 'contract': 1,\n",
       " 'chipmaker': 1,\n",
       " 'spend': 1,\n",
       " '2.12': 1,\n",
       " 'equity': 1,\n",
       " 'investment': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_wordcount = crawler.word_count(orignal_text)\n",
    "result_wordcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 將聲量結果儲存到Excel\n",
    "#### 使用get_wordcount_json function濾掉不要的word count dict, 取自己要的(whitelist)\n",
    "#### 同時利用jsonarray_toexcel function將結果，落地於Excel，以做聲量分析\n",
    "```\n",
    "def get_wordcount_json(self,whitelist , dict_data):\n",
    "        data_array = []\n",
    "        for i in whitelist:\n",
    "            json_data = {\n",
    "                'Date' : 'Week1',\n",
    "                'Company' : i , \n",
    "                'Count' : dict_data[i]\n",
    "            }\n",
    "            data_array.append(json_data)\n",
    "        return data_array\n",
    "def jsonarray_toexcel(self,data_array):\n",
    "    df = pd.DataFrame(data=data_array)\n",
    "    df.to_excel('result.xlsx' , index=False)\n",
    "    return\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Date': 'Week1', 'Company': 'ASML', 'Count': 7}, {'Date': 'Week1', 'Company': 'Intel', 'Count': 5}]\n",
      "Excel is OK\n"
     ]
    }
   ],
   "source": [
    "whitelist = ['ASML' , 'Intel']\n",
    "end_result = crawler.get_wordcount_json(whitelist , result_wordcount)\n",
    "print(end_result)\n",
    "crawler.jsonarray_toexcel(end_result)\n",
    "print('Excel is OK')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
